{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Pandas Operations\n",
    "\n",
    "In this notebook we review some of the key advanced Pandas operations.  \n",
    "\n",
    "* **groupby:** grouping collections of records that share the same value for one set of fields and then computing aggregate statistic over the remaining fields\n",
    "\n",
    "* **pivot:** similar to groupby except the results are presented slightly differently ... \n",
    "\n",
    "* **merge:** *join* data from a pair of dataframes into a single dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate these operations we will use some toy data about peoples favorite colors and numbers.  To protect peoples identities their favorite numbers and colors are fictional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.520283Z",
     "start_time": "2018-01-28T23:09:42.037192Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people = pd.DataFrame(\n",
    "    [[\"Joey\",      \"blue\",    42,  \"M\"],\n",
    "     [\"Weiwei\",    \"blue\",    50,  \"F\"],\n",
    "     [\"Joey\",      \"green\",    8,  \"M\"],\n",
    "     [\"Karina\",    \"green\",    7,  \"F\"],\n",
    "     [\"Fernando\",  \"pink\",    -9,  \"M\"],\n",
    "     [\"Nhi\",       \"blue\",     3,  \"F\"],\n",
    "     [\"Sam\",       \"pink\",   -42,  \"M\"]], \n",
    "    columns = [\"Name\", \"Color\", \"Number\", \"Sex\"])\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "The `groupby` operator groups rows in the table that are the same in one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.527174Z",
     "start_time": "2018-01-28T23:09:42.522396Z"
    }
   },
   "outputs": [],
   "source": [
    "grps = people.groupby(\"Color\")\n",
    "grps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.535068Z",
     "start_time": "2018-01-28T23:09:42.528985Z"
    }
   },
   "outputs": [],
   "source": [
    "grps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.565752Z",
     "start_time": "2018-01-28T23:09:42.536987Z"
    }
   },
   "outputs": [],
   "source": [
    "grps.apply(lambda df: display(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.584411Z",
     "start_time": "2018-01-28T23:09:42.568749Z"
    }
   },
   "outputs": [],
   "source": [
    "people.loc[grps.indices[\"blue\"],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will commonly combine `groupby` with column selection (e.g., `df.groupby(\"Region\")[\"Sales\"]`) and then finally adding some aggregate calculation on that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.592225Z",
     "start_time": "2018-01-28T23:09:42.586598Z"
    }
   },
   "outputs": [],
   "source": [
    "people.groupby(\"Color\")[\"Number\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.599977Z",
     "start_time": "2018-01-28T23:09:42.594488Z"
    }
   },
   "outputs": [],
   "source": [
    "people.groupby(\"Color\")[\"Number\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.608952Z",
     "start_time": "2018-01-28T23:09:42.602811Z"
    }
   },
   "outputs": [],
   "source": [
    "people.groupby(\"Color\")[\"Number\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we can group by one **or more** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.616442Z",
     "start_time": "2018-01-28T23:09:42.610570Z"
    }
   },
   "outputs": [],
   "source": [
    "people.groupby([\"Color\", \"Sex\"])['Number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.627405Z",
     "start_time": "2018-01-28T23:09:42.618129Z"
    }
   },
   "outputs": [],
   "source": [
    "people.groupby([\"Color\", \"Sex\"])[['Name','Number']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.649906Z",
     "start_time": "2018-01-28T23:09:42.629380Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def avg_str_len(series):\n",
    "    return series.str.len().mean()\n",
    "\n",
    "res = (\n",
    "    people\n",
    "        .groupby([\"Color\", \"Sex\"])\n",
    "        .aggregate({\"Name\": avg_str_len, \"Number\": np.mean})\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and Indexes\n",
    "\n",
    "Notice that the `groupby` operation creates an index based on the grouping columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.662788Z",
     "start_time": "2018-01-28T23:09:42.653379Z"
    }
   },
   "outputs": [],
   "source": [
    "res.loc[['blue','F'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.673044Z",
     "start_time": "2018-01-28T23:09:42.664856Z"
    }
   },
   "outputs": [],
   "source": [
    "res.loc[['green'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases we might want to leave the grouping fields as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.690751Z",
     "start_time": "2018-01-28T23:09:42.675272Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    people\n",
    "        .groupby([\"Color\", \"Sex\"], as_index=False)\n",
    "        .aggregate({\"Name\": \"first\", \"Number\": np.mean})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot\n",
    "\n",
    "Pivot is used to examine aggregates with respect to two characteristics.  You might construct a pivot of sales data if you wanted to look at average sales broken down by year and market.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pivot operation is essentially a `groupby` operation that transforms the rows *and the columns.*   For example consider the following **groupby** operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.698946Z",
     "start_time": "2018-01-28T23:09:42.692803Z"
    }
   },
   "outputs": [],
   "source": [
    "people.groupby([\"Color\", \"Sex\"])['Number'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pivot` to compute the same result but displayed slightly differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.713447Z",
     "start_time": "2018-01-28T23:09:42.700932Z"
    }
   },
   "outputs": [],
   "source": [
    "people.pivot_table(\n",
    "    values  = \"Number\", # the entry to aggregate over\n",
    "    index   = \"Color\",  # the row grouping attributes\n",
    "    columns = \"Sex\",    # the column grouping attributes\n",
    "    aggfunc = \"count\"   # the aggregation function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "1. the second \"grouping\" column (`Sex`) has been **\"pivoted\" from the rows to column location**. \n",
    "1. there is a missing value for `pink` and `F` since none of the females chose `pink` as their favorite color.\n",
    "\n",
    "We can specify how missing values are filled in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.734690Z",
     "start_time": "2018-01-28T23:09:42.715159Z"
    }
   },
   "outputs": [],
   "source": [
    "people.pivot_table(\n",
    "    values  = \"Number\",\n",
    "    index   = \"Color\",\n",
    "    columns = \"Sex\",\n",
    "    aggfunc = \"count\",\n",
    "    fill_value = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging (joining)\n",
    "\n",
    "The **merge** operation combines data from two dataframes into one dataframe. The **merge** operation in Pandas behaves like a **join** operation in SQL (we will cover SQL joins later in the semester).  Unfortunately, Pandas also offers a `join` function which is a limited version of `merge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I also have a list of email addresses that I would like to combine with my `people` dataframe from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.748615Z",
     "start_time": "2018-01-28T23:09:42.738687Z"
    }
   },
   "outputs": [],
   "source": [
    "email = pd.DataFrame(\n",
    "    [[\"Deb\",  \"deborah_nolan@berkeley.edu\"],\n",
    "     [\"Sam\",  \"samlau95@berkeley.edu\"],\n",
    "     [\"John\", \"doe@nope.com\"],\n",
    "     [\"Joey\", \"jegonzal@cs.berkeley.edu\"],\n",
    "     [\"Weiwei\", \"weiwzhang@berkeley.edu\"],\n",
    "     [\"Weiwei\", \"weiwzhang+123@berkeley.edu\"],\n",
    "     [\"Karina\", \"kgoot@berkeley.edu\"]], \n",
    "    columns = [\"User Name\", \"Email\"])\n",
    "email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can use the merge function to combine these two tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.762403Z",
     "start_time": "2018-01-28T23:09:42.750275Z"
    }
   },
   "outputs": [],
   "source": [
    "people.merge(email, \n",
    "            how = \"inner\",\n",
    "            left_on = \"Name\", right_on = \"User Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "1. the output dataframe only contains rows that have names in both tables.  For example, `Fernando` didn't have an email address and `Deb` didn't have a color preference.\n",
    "1. The name `Joey` occurred twice in the people table and shows up twice in the output. \n",
    "1. The name `Weiwei` occurred twice in the email table and appears twice in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How could we fix the duplicate entries?\n",
    "\n",
    "We could group by name (or by email) and take only the first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.786255Z",
     "start_time": "2018-01-28T23:09:42.763919Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    people\n",
    "        .merge(email, \n",
    "            how = \"inner\",\n",
    "            left_on = \"Name\", right_on = \"User Name\")\n",
    "        .groupby('Name').first()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Joins\n",
    "\n",
    "The above join was an inner join.  What if we wanted to keep all of the people and leave missing in the email address field when their email addresses are not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.799162Z",
     "start_time": "2018-01-28T23:09:42.787763Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people.merge(email, \n",
    "            how = \"left\",\n",
    "            left_on = \"Name\", right_on = \"User Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.813970Z",
     "start_time": "2018-01-28T23:09:42.801079Z"
    }
   },
   "outputs": [],
   "source": [
    "people.merge(email, \n",
    "            how = \"right\",\n",
    "            left_on = \"Name\", right_on = \"User Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:42.832796Z",
     "start_time": "2018-01-28T23:09:42.816408Z"
    }
   },
   "outputs": [],
   "source": [
    "people.merge(email, \n",
    "            how = \"outer\",\n",
    "            left_on = \"Name\", right_on = \"User Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finishing the Baby Names Lecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:43.463389Z",
     "start_time": "2018-01-28T23:09:42.834904Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is a useful helper for downloading and caching data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:43.514855Z",
     "start_time": "2018-01-28T23:09:43.465416Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded \n",
    "    \n",
    "    return: The pathlib.Path object representing the file.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from pathlib import Path\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        print('Downloading...', end=' ')\n",
    "        resp = requests.get(data_url)\n",
    "        with file_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        import time \n",
    "        birth_time = time.ctime(file_path.stat().st_birthtime)\n",
    "        print(\"Using cached version downloaded:\", birth_time)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:43.615150Z",
     "start_time": "2018-01-28T23:09:43.516585Z"
    }
   },
   "outputs": [],
   "source": [
    "data_url = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "namesbystate_path = fetch_and_cache(data_url, 'namesbystate.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:47.265068Z",
     "start_time": "2018-01-28T23:09:43.617243Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zf = zipfile.ZipFile(namesbystate_path, 'r')\n",
    "\n",
    "field_names = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "\n",
    "def load_dataframe_from_zip(zf, f):\n",
    "    with zf.open(f) as fh: \n",
    "        return pd.read_csv(fh, header=None, names=field_names)\n",
    "        \n",
    "states = [\n",
    "    load_dataframe_from_zip(zf, f)\n",
    "    for f in sorted(zf.filelist, key=lambda x:x.filename) \n",
    "    if f.filename.endswith('.TXT')\n",
    "]\n",
    "\n",
    "baby_names = pd.concat(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Can I deduce birth sex from the last letter of a personâ€™s name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:49.010215Z",
     "start_time": "2018-01-28T23:09:47.267017Z"
    }
   },
   "outputs": [],
   "source": [
    "baby_names['Last Letter'] = baby_names['Name'].str[-1]\n",
    "baby_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:49.016266Z",
     "start_time": "2018-01-28T23:09:49.012598Z"
    }
   },
   "outputs": [],
   "source": [
    "baby_names.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How common is each last letter?\n",
    "\n",
    "We can use the `groupby` operation to determine the total number of registered babies with last names ending in each letter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:49.784618Z",
     "start_time": "2018-01-28T23:09:49.018115Z"
    }
   },
   "outputs": [],
   "source": [
    "last_letter_totals = baby_names.groupby('Last Letter')['Count'].sum()\n",
    "last_letter_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:50.201955Z",
     "start_time": "2018-01-28T23:09:49.786716Z"
    }
   },
   "outputs": [],
   "source": [
    "last_letter_totals.plot.bar(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by Birth Sex\n",
    "\n",
    "We can use the `pivot` operation to break the last letter of each name down by the birth sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:50.857012Z",
     "start_time": "2018-01-28T23:09:50.203954Z"
    }
   },
   "outputs": [],
   "source": [
    "last_letter_pivot = baby_names.pivot_table(\n",
    "    values='Count', # the field(s) to processed in each group\n",
    "    index='Last Letter', # the rows (turned into index)\n",
    "    columns='Sex', # the column values\n",
    "    aggfunc=sum, # group operation\n",
    ")\n",
    "last_letter_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:51.148233Z",
     "start_time": "2018-01-28T23:09:50.858762Z"
    }
   },
   "outputs": [],
   "source": [
    "last_letter_pivot.plot.bar(figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the total counts.  We might instead be interested in the proportion of males or females ending in each letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:51.166028Z",
     "start_time": "2018-01-28T23:09:51.150233Z"
    }
   },
   "outputs": [],
   "source": [
    "prop_last_letter_pivot = last_letter_pivot.div(last_letter_totals, axis=0)\n",
    "prop_last_letter_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:51.536896Z",
     "start_time": "2018-01-28T23:09:51.167814Z"
    }
   },
   "outputs": [],
   "source": [
    "prop_last_letter_pivot.plot.bar(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we display the bars in order of the proportion of males we get a much clearer picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T23:09:51.857098Z",
     "start_time": "2018-01-28T23:09:51.538854Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    prop_last_letter_pivot\n",
    "        .sort_values(\"M\")\n",
    "        .plot.bar(figsize=(10, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
